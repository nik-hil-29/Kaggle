{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":61542,"databundleVersionId":6888007,"sourceType":"competition"},{"sourceId":6977472,"sourceType":"datasetVersion","datasetId":4005256}],"dockerImageVersionId":30559,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2024-01-17T18:52:32.623097Z","iopub.execute_input":"2024-01-17T18:52:32.623782Z","iopub.status.idle":"2024-01-17T18:52:32.638387Z","shell.execute_reply.started":"2024-01-17T18:52:32.623677Z","shell.execute_reply":"2024-01-17T18:52:32.636878Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.model_selection import StratifiedKFold, train_test_split\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.ensemble import VotingClassifier, RandomForestClassifier\nfrom sklearn.metrics import roc_auc_score\nfrom catboost import CatBoostClassifier\nfrom lightgbm import LGBMClassifier\n\n\nfrom transformers import PreTrainedTokenizerFast\nfrom tokenizers import (\n    decoders,\n    models,\n    normalizers,\n    pre_tokenizers,\n    processors,\n    trainers,\n    Tokenizer,\n)\n\n\nfrom datasets import Dataset\nfrom tqdm.auto import tqdm\nimport pandas as pd\nimport numpy as np\nimport sys\nimport gc","metadata":{"execution":{"iopub.status.busy":"2024-01-17T18:52:32.640848Z","iopub.execute_input":"2024-01-17T18:52:32.642057Z","iopub.status.idle":"2024-01-17T18:52:32.653225Z","shell.execute_reply.started":"2024-01-17T18:52:32.642007Z","shell.execute_reply":"2024-01-17T18:52:32.651814Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"test = pd.read_csv('/kaggle/input/llm-detect-ai-generated-text/test_essays.csv')\nsub = pd.read_csv('/kaggle/input/llm-detect-ai-generated-text/sample_submission.csv')\n# train = pd.read_csv(\"/kaggle/input/daigt-v2-train-dataset/train_v2_drcat_02.csv\", sep=',')","metadata":{"execution":{"iopub.status.busy":"2024-01-17T18:52:32.655415Z","iopub.execute_input":"2024-01-17T18:52:32.656230Z","iopub.status.idle":"2024-01-17T18:52:32.692778Z","shell.execute_reply.started":"2024-01-17T18:52:32.656197Z","shell.execute_reply":"2024-01-17T18:52:32.691824Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv(\"/kaggle/input/ai-generated-vs-human-generated/merge.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-01-17T18:56:02.046467Z","iopub.execute_input":"2024-01-17T18:56:02.046982Z","iopub.status.idle":"2024-01-17T18:56:12.033098Z","shell.execute_reply.started":"2024-01-17T18:56:02.046932Z","shell.execute_reply":"2024-01-17T18:56:12.031836Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"train = train.drop_duplicates(subset=['text'])\ntrain.reset_index(drop=True, inplace=True)\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2024-01-17T18:58:44.728136Z","iopub.execute_input":"2024-01-17T18:58:44.728666Z","iopub.status.idle":"2024-01-17T18:58:45.102157Z","shell.execute_reply.started":"2024-01-17T18:58:44.728628Z","shell.execute_reply":"2024-01-17T18:58:45.100878Z"},"trusted":true},"execution_count":39,"outputs":[{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"   Unnamed: 0         prompt_name  \\\n0           0  Phones and driving   \n1           1  Phones and driving   \n2           2  Phones and driving   \n3           3  Phones and driving   \n4           4  Phones and driving   \n\n                                                text  generated  \\\n0  Phones\\n\\nModern humans today are always on th...          0   \n1  This essay will explain if drivers should or s...          0   \n2  Driving while the use of cellular devices\\n\\nT...          0   \n3  Phones & Driving\\n\\nDrivers should not be able...          0   \n4  Cell Phone Operation While Driving\\n\\nThe abil...          0   \n\n            source                                          file  \n0  persuade_corpus  daigt-v2-train-dataset/train_v2_drcat_02.csv  \n1  persuade_corpus  daigt-v2-train-dataset/train_v2_drcat_02.csv  \n2  persuade_corpus  daigt-v2-train-dataset/train_v2_drcat_02.csv  \n3  persuade_corpus  daigt-v2-train-dataset/train_v2_drcat_02.csv  \n4  persuade_corpus  daigt-v2-train-dataset/train_v2_drcat_02.csv  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>prompt_name</th>\n      <th>text</th>\n      <th>generated</th>\n      <th>source</th>\n      <th>file</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>Phones and driving</td>\n      <td>Phones\\n\\nModern humans today are always on th...</td>\n      <td>0</td>\n      <td>persuade_corpus</td>\n      <td>daigt-v2-train-dataset/train_v2_drcat_02.csv</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>Phones and driving</td>\n      <td>This essay will explain if drivers should or s...</td>\n      <td>0</td>\n      <td>persuade_corpus</td>\n      <td>daigt-v2-train-dataset/train_v2_drcat_02.csv</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>Phones and driving</td>\n      <td>Driving while the use of cellular devices\\n\\nT...</td>\n      <td>0</td>\n      <td>persuade_corpus</td>\n      <td>daigt-v2-train-dataset/train_v2_drcat_02.csv</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>Phones and driving</td>\n      <td>Phones &amp; Driving\\n\\nDrivers should not be able...</td>\n      <td>0</td>\n      <td>persuade_corpus</td>\n      <td>daigt-v2-train-dataset/train_v2_drcat_02.csv</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>Phones and driving</td>\n      <td>Cell Phone Operation While Driving\\n\\nThe abil...</td>\n      <td>0</td>\n      <td>persuade_corpus</td>\n      <td>daigt-v2-train-dataset/train_v2_drcat_02.csv</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"train[\"generated\"].value_counts()","metadata":{"execution":{"iopub.status.busy":"2024-01-17T18:58:59.938452Z","iopub.execute_input":"2024-01-17T18:58:59.938946Z","iopub.status.idle":"2024-01-17T18:58:59.951078Z","shell.execute_reply.started":"2024-01-17T18:58:59.938884Z","shell.execute_reply":"2024-01-17T18:58:59.949858Z"},"trusted":true},"execution_count":40,"outputs":[{"execution_count":40,"output_type":"execute_result","data":{"text/plain":"generated\n1    124308\n0     66036\nName: count, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"excluded_prompt_name_list = ['Distance learning','Grades for extracurricular activities','Summer projects']\ntrain = train[~(train['prompt_name'].isin(excluded_prompt_name_list))]\ntrain = train.drop_duplicates(subset=['text'])\ntrain.reset_index(drop=True, inplace=True)","metadata":{"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"test.text.values","metadata":{"execution":{"iopub.status.busy":"2024-01-17T18:59:05.538426Z","iopub.execute_input":"2024-01-17T18:59:05.538839Z","iopub.status.idle":"2024-01-17T18:59:05.547047Z","shell.execute_reply.started":"2024-01-17T18:59:05.538809Z","shell.execute_reply":"2024-01-17T18:59:05.545668Z"},"trusted":true},"execution_count":42,"outputs":[{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"array(['Aaa bbb ccc.', 'Bbb ccc ddd.', 'CCC ddd eee.'], dtype=object)"},"metadata":{}}]},{"cell_type":"code","source":"LOWERCASE = False\nVOCAB_SIZE = 14_000_000","metadata":{"execution":{"iopub.status.busy":"2024-01-17T18:59:09.476623Z","iopub.execute_input":"2024-01-17T18:59:09.477065Z","iopub.status.idle":"2024-01-17T18:59:09.483012Z","shell.execute_reply.started":"2024-01-17T18:59:09.477032Z","shell.execute_reply":"2024-01-17T18:59:09.481665Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"# Creating Byte-Pair Encoding tokenizer\nraw_tokenizer = Tokenizer(models.BPE(unk_token=\"[UNK]\"))\n\n\n# Adding normalization and pre_tokenizer\nraw_tokenizer.normalizer = normalizers.Sequence(\n    [normalizers.NFC()] + [normalizers.Lowercase()] \n    if LOWERCASE else []\n)\n\n\nraw_tokenizer.pre_tokenizer = pre_tokenizers.ByteLevel()\n\n# Adding special tokens and creating trainer instance\nspecial_tokens = [\"[UNK]\", \"[PAD]\", \"[CLS]\", \"[SEP]\", \"[MASK]\"]\ntrainer = trainers.BpeTrainer(\n    vocab_size=VOCAB_SIZE, \n    special_tokens=special_tokens\n)\n\n\n# Creating huggingface dataset object\ndataset = Dataset.from_pandas(test[['text']])\n\ndef train_corp_iter():\n    \"\"\"\n    A generator function for iterating over a dataset in chunks.\n    \"\"\"    \n    for i in range(0, len(dataset), 1000):\n        yield dataset[i : i + 1000][\"text\"]\n\n# Training from iterator REMEMBER it's training on test set...\nraw_tokenizer.train_from_iterator(train_corp_iter(), trainer=trainer)\n\ntokenizer = PreTrainedTokenizerFast(\n    tokenizer_object=raw_tokenizer,\n    unk_token  = \"[UNK]\",\n    pad_token  = \"[PAD]\",\n    cls_token  = \"[CLS]\",\n    sep_token  = \"[SEP]\",\n    mask_token = \"[MASK]\",\n)\n\n\n\n# Tokenize test set with new tokenizer\ntokenized_texts_test = []\nfor text in tqdm(test['text'].tolist()):\n    tokenized_texts_test.append(tokenizer.tokenize(text))\n\n\n# Tokenize train set\ntokenized_texts_train = []\nfor text in tqdm(train['text'].tolist()):\n    tokenized_texts_train.append(tokenizer.tokenize(text))","metadata":{"execution":{"iopub.status.busy":"2024-01-17T18:59:11.827669Z","iopub.execute_input":"2024-01-17T18:59:11.828108Z","iopub.status.idle":"2024-01-17T19:12:21.644657Z","shell.execute_reply.started":"2024-01-17T18:59:11.828076Z","shell.execute_reply":"2024-01-17T19:12:21.643191Z"},"trusted":true},"execution_count":45,"outputs":[{"name":"stdout","text":"\n\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6e98326fd8034980a003fd44a4270428"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/179453 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2784a2d7ff874d319e34489e77c2028d"}},"metadata":{}}]},{"cell_type":"code","source":"print(tokenized_texts_test[1])\nprint()\nprint(tokenized_texts_test[2])","metadata":{"execution":{"iopub.status.busy":"2024-01-17T19:14:44.725131Z","iopub.execute_input":"2024-01-17T19:14:44.725742Z","iopub.status.idle":"2024-01-17T19:14:44.735308Z","shell.execute_reply.started":"2024-01-17T19:14:44.725703Z","shell.execute_reply":"2024-01-17T19:14:44.733811Z"},"trusted":true},"execution_count":46,"outputs":[{"name":"stdout","text":"['ĠBbb', 'Ġccc', 'Ġddd', '.']\n\n['ĠCCC', 'Ġddd', 'Ġeee', '.']\n","output_type":"stream"}]},{"cell_type":"code","source":"def dummy(text):\n    \"\"\"\n    A dummy function to use as tokenizer for TfidfVectorizer. \n    It returns the text as it is since we already tokenized it.\n    \"\"\"\n    return text\n\n\n\n# Fitting TfidfVectoizer on test set\nvectorizer = TfidfVectorizer(\n    ngram_range   = (3, 5), \n    lowercase     = False, \n    sublinear_tf  = True, \n    analyzer      = 'word',\n    tokenizer     = dummy,\n    preprocessor  = dummy,\n    token_pattern = None, \n    strip_accents ='unicode')\n\n\nvectorizer.fit(tokenized_texts_test)\n\n# Getting vocab\nvocab = vectorizer.vocabulary_\nprint(vocab)\n\n\n# Here we fit our vectorizer on train set but this time we use vocabulary from test fit.\nvectorizer = TfidfVectorizer(\n    ngram_range    = (3, 5), \n    lowercase      = False, \n    sublinear_tf   = True, \n    vocabulary     = vocab,\n    analyzer       = 'word',\n    tokenizer      = dummy,\n    preprocessor   = dummy,\n    token_pattern  = None, \n    strip_accents  ='unicode')\n\ntf_train = vectorizer.fit_transform(tokenized_texts_train)\ntf_test = vectorizer.transform(tokenized_texts_test)\ndel vectorizer\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2024-01-17T19:15:00.227682Z","iopub.execute_input":"2024-01-17T19:15:00.229616Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"{'ĠAaa Ġbbb Ġccc': 0, 'Ġbbb Ġccc .': 6, 'ĠAaa Ġbbb Ġccc .': 1, 'ĠBbb Ġccc Ġddd': 2, 'Ġccc Ġddd .': 7, 'ĠBbb Ġccc Ġddd .': 3, 'ĠCCC Ġddd Ġeee': 4, 'Ġddd Ġeee .': 8, 'ĠCCC Ġddd Ġeee .': 5}\n","output_type":"stream"}]},{"cell_type":"code","source":"y_train_label = train['generated'].values","metadata":{"execution":{"iopub.status.busy":"2024-01-17T18:54:22.053537Z","iopub.execute_input":"2024-01-17T18:54:22.053976Z","iopub.status.idle":"2024-01-17T18:54:22.060398Z","shell.execute_reply.started":"2024-01-17T18:54:22.053941Z","shell.execute_reply":"2024-01-17T18:54:22.058875Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"tf_train","metadata":{"execution":{"iopub.status.busy":"2024-01-17T18:54:24.012309Z","iopub.execute_input":"2024-01-17T18:54:24.013227Z","iopub.status.idle":"2024-01-17T18:54:24.020537Z","shell.execute_reply.started":"2024-01-17T18:54:24.013172Z","shell.execute_reply":"2024-01-17T18:54:24.019512Z"},"trusted":true},"execution_count":34,"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"<1378x9 sparse matrix of type '<class 'numpy.float64'>'\n\twith 0 stored elements in Compressed Sparse Row format>"},"metadata":{}}]},{"cell_type":"code","source":"tf_train.shape","metadata":{"execution":{"iopub.status.busy":"2024-01-17T18:54:26.575805Z","iopub.execute_input":"2024-01-17T18:54:26.576668Z","iopub.status.idle":"2024-01-17T18:54:26.584742Z","shell.execute_reply.started":"2024-01-17T18:54:26.576620Z","shell.execute_reply":"2024-01-17T18:54:26.583783Z"},"trusted":true},"execution_count":35,"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"(1378, 9)"},"metadata":{}}]},{"cell_type":"code","source":"tf_test.shape","metadata":{"execution":{"iopub.status.busy":"2024-01-17T18:54:28.579324Z","iopub.execute_input":"2024-01-17T18:54:28.579740Z","iopub.status.idle":"2024-01-17T18:54:28.587979Z","shell.execute_reply.started":"2024-01-17T18:54:28.579710Z","shell.execute_reply":"2024-01-17T18:54:28.586601Z"},"trusted":true},"execution_count":36,"outputs":[{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"(3, 9)"},"metadata":{}}]},{"cell_type":"code","source":"if len(test.text.values) <= 5:\n    sub.to_csv('submission.csv', index=False)\nelse:\n    clf = MultinomialNB(alpha=0.0225)\n    \n    sgd_model = SGDClassifier(\n        max_iter     = 9000, \n        tol          = 1e-4, \n        random_state = 6743,\n        loss         = \"modified_huber\"\n    ) \n    \n    p={\n        'verbose'          : -1,\n        'n_iter'           : 3000,\n        'colsample_bytree' : 0.7800,\n        'colsample_bynode' : 0.8000, \n        'random_state'     : 6743,\n        'metric'           : 'auc',\n        'objective'        : 'cross_entropy',\n        'learning_rate'    : 0.00581909898961407, \n      }\n    lgb=LGBMClassifier(**p)\n    \n    \n    cat = CatBoostClassifier(\n        iterations        = 3000,\n        verbose           = 0,\n        subsample         = 0.35,\n        random_seed       = 6543,\n        allow_const_label = True,\n        loss_function     = 'CrossEntropy',\n        learning_rate     = 0.005599066836106983,\n    )\n    \n    \n    ensemble = VotingClassifier(\n        estimators = [('mnb', clf),\n                      ('sgd', sgd_model),\n                      ('lgb', lgb), \n                      ('cat', cat)],\n        weights    = [0.1, 0.31, 0.28, 0.67], \n        voting     = 'soft', \n        n_jobs     = -1\n    )\n    \n    ensemble.fit(tf_train, y_train_label)\n    gc.collect()\n    \n    final_preds = ensemble.predict_proba(tf_test)[:,1]\n    sub['generated'] = final_preds\n    sub.to_csv('submission.csv', index=False)\n    sub.head()","metadata":{"execution":{"iopub.status.busy":"2024-01-17T18:54:30.843977Z","iopub.execute_input":"2024-01-17T18:54:30.844946Z","iopub.status.idle":"2024-01-17T18:54:30.858998Z","shell.execute_reply.started":"2024-01-17T18:54:30.844898Z","shell.execute_reply":"2024-01-17T18:54:30.857251Z"},"trusted":true},"execution_count":37,"outputs":[]}]}